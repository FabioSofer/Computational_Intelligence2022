{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "## Deadlines ([AoE](https://en.wikipedia.org/wiki/Anywhere_on_Earth))\n",
    "\n",
    "* Sunday, December 4th for Task3.1 and Task3.2\n",
    "* Sunday, December 11th for Task3.3 and Task3.4\n",
    "* Sunday, December 18th for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        rowList=list(self._rows)\n",
    "        rowList.sort()\n",
    "        return hash(\" \".join(str(_) for _ in self._rows))\n",
    "\n",
    "    def __eq__(self, __o: object) -> bool:\n",
    "        return (self.__hash__()==__o.__hash__())\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1: Expert Player (same as Professor's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    *_, result = accumulate(state.rows, xor)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim,nimSum=False) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    if nimSum:\n",
    "        cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "        brute_force = list()\n",
    "        for m in cooked[\"possible_moves\"]:\n",
    "            tmp = deepcopy(state)\n",
    "            tmp.nimming(m)\n",
    "            brute_force.append((m, nim_sum(tmp)))\n",
    "        cooked[\"brute_force\"] = brute_force\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_startegy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state,True)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), random.choice(data[\"brute_force\"]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MATCHES = 100\n",
    "NIM_SIZE = 20\n",
    "\n",
    "\n",
    "def evaluate(strategy: Callable,opponent) -> float:\n",
    "    opponent = (strategy, opponent)\n",
    "    won = 0\n",
    "\n",
    "    for m in range(NUM_MATCHES):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = opponent[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / NUM_MATCHES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2 -> Evolutionary Alg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_evolutionary_strategy(genome: dict) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "        data = cook_status(state)\n",
    "\n",
    "        if data[\"active_rows_number\"]==1:\n",
    "            ply=Nimply(data[\"shortest_row\"],state.rows[data[\"shortest_row\"]])\n",
    "            return ply\n",
    "\n",
    "        if random.random() < genome[\"p\"]:\n",
    "            #Take Everything\n",
    "            ply=Nimply(data[\"shortest_row\"],state.rows[data[\"shortest_row\"]])\n",
    "        else:\n",
    "            #Take Everything but 1\n",
    "            rowChoice=random.choice([x[0] for x in enumerate(state.rows) if x[1]!=0])\n",
    "            ply=Nimply(rowChoice,state.rows[rowChoice] if state.rows[rowChoice]==1 else state.rows[rowChoice]-1)\n",
    "        return ply\n",
    "\n",
    "    return evolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GEN=100\n",
    "\n",
    "\n",
    "def evolve(strat:Callable,opponent):\n",
    "    genome={\"p\":0.5}\n",
    "    lostMatchesCounter=0\n",
    "    prevWR=evaluate(strat(genome),opponent)  \n",
    "    direction=+0.05\n",
    "    for i in range(NUM_GEN):\n",
    "        sign=(direction/abs(direction)) #current sign of direction + or -\n",
    "\n",
    "        if lostMatchesCounter==0: #if you just made a mistake, double check\n",
    "            genome[\"p\"]+=direction\n",
    "        newStrat=strat(genome)\n",
    "        wr=evaluate(newStrat,opponent)\n",
    "        if(prevWR<=wr):\n",
    "            lostMatchesCounter=0\n",
    "            direction=min(direction*1.2,0.1*sign) #we slowly gain confidence in our direction,\n",
    "            # up to a maximum accelleration of .1\n",
    "        else :\n",
    "            lostMatchesCounter+=1\n",
    "            direction=0.05*sign#reset step to 0.05\n",
    "            if lostMatchesCounter>=2:\n",
    "                direction=-direction #set to flipped sign\n",
    "                lostMatchesCounter=0\n",
    "        \n",
    "        prevWR=wr\n",
    "        print(f\"Round {i+1}: WR:{wr} with P:{genome['p']}\")\n",
    "    return genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "#Evolve him for the matchup\n",
    "strategy = (make_evolutionary_strategy(\n",
    "    evolve(make_evolutionary_strategy,pure_random)\n",
    "),pure_random)\n",
    "#play the \"real\" game\n",
    "nim = Nim(7)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)[0]\n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3 -> MinMax Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_val(board:Nim):\n",
    "    #if there is only one row left you have won\n",
    "    if sum(o > 0 for o in board.rows)==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "boardCache=dict()\n",
    "\n",
    "#wrapper for the recursive minmax_rec, used to discard val and only return ply\n",
    "def minmax(board:Nim):\n",
    "    return minmax_rec(board)[0]\n",
    "\n",
    "def minmax_rec(board:Nim):\n",
    "    #check if the state is already evaluated to avoid recomputation\n",
    "    if board in boardCache.keys() :\n",
    "        return boardCache[board]\n",
    "    val = get_val(board)\n",
    "    possible = [(r, o) for r, c in enumerate(board.rows) for o in range(1,c+1)] \n",
    "    #we sort the possible moves in decreasing order based on the number of elements removed\n",
    "    possible.sort(reverse=True,key=lambda k: k[1]) \n",
    "    if val != 0:\n",
    "        #if someone has won return the move and its val\n",
    "        return possible[0],val\n",
    "    evaluations = list()\n",
    "    for ply in possible:\n",
    "        newBoard=deepcopy(board) #return new board\n",
    "        newBoard.nimming(ply)\n",
    "        _, val = minmax_rec(newBoard)\n",
    "        evaluations.append((ply, -val))\n",
    "        if(val==-1):\n",
    "            #as we are returning only the max we stop as soon as we get -1 (because it is saved as -val)\n",
    "            break\n",
    "    #we cache the evaluation of the current state\n",
    "    boardCache[board]=max(evaluations, key=lambda k: k[1])\n",
    "    return max(evaluations, key=lambda k: k[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "NUM_ROWS = 6\n",
    "\n",
    "strategy = ()\n",
    "nim = Nim(NUM_ROWS)\n",
    "\n",
    "#We check which player should start in order not to lose automatically against the optimal strategy\n",
    "minmax_player = int(nim_sum(nim) == 0)\n",
    "logging.debug(f\"We are player {minmax_player}\")\n",
    "if minmax_player == 1:\n",
    "    strategy = (optimal_startegy,minmax)\n",
    "else:\n",
    "    strategy = (minmax,optimal_startegy)\n",
    "\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
